window.projects = [
    {
        "id": "spectral-subjects",
        "title": "SPECTRAL SUBJECTS",
        "year": null,
        "client": "Rafael Lozano-Hemmer / MOCA Jacksonville",
        "role": null,
        "technologies": null,
        "description": "Thermographic cameras, projection mapping, Développement d'une carte thermique interactive de l'espace",
        "impact": null,
        "media": [
            "https://www.instagram.com/lozanohemmer/"
        ],
        "instagram": [
            "https://www.instagram.com/lozanohemmer/"
        ],
        "cover": null,
        "hasMedia": true,
        "fullDescription": "“Spectral Subjects” is a thermal observatory that displays a constantly updating map of the room's temperature. Using thermographic cameras, the project detects heat and cold in the environment, including the building’s air circulation and ventilation, visitors’ body heat, and inanimate objects. As temperature is detected, the artwork creates a visible manifestation of the public’s “heat signature” in various ways, mixing live feeds with recently past heat signatures, materializing thermal echoes of the atmosphere, and creating an evolving portrait of uncanny spectral traces that make the atmosphere tangible. The artwork has two versions: a unique projection-based treatment that can be adapted to any architecture, and an edition that can be adapted to flatscreens of different sizes.\n**Technical details and implementation**High-sensitivity thermographic cameras (Xenics Dione class) capture temperature variations in real-timeCustom GPU processing transforms thermal data into flowing particle systems with temporal persistenceLarge-scale architectural projection calibrated for the atrium's unique surfaces and lighting conditionsMultiple editions: immersive projection version and intimate screen-based installations**Challenges and solutions**Complex thermal backgrounds required per-site calibration and adaptive threshold algorithmsAchieving responsive interaction demanded optimized GPU pipelines with minimal latencyBalancing signal clarity with ambient noise through temporal filteringArchitectural projection mapping required precise geometric calibration and keystone correction**Impact and results**Makes the invisible exchanges of daily life—heat, breath, presence—visually tangibleVisitors become co-authors of the workExhibited Dec 2024–Jun 2025 at MOCA Jacksonville as part of centennial programmingGenerated exceptional public engagement through intuitive, immediate interaction**Process and methodology**Comprehensive site analysis including thermal mapping, HVAC patterns, and lighting studiesIterative prototyping of diffusion algorithms and visual palettesOn-site installation with continuous tuning based on real visitor behavior patterns---"
    },
    {
        "id": "climate-parliament",
        "title": "CLIMATE PARLIAMENT",
        "year": null,
        "client": "Rafael Lozano-Hemmer / Rice University",
        "role": null,
        "technologies": null,
        "description": "Audio-reactive lighting, interactive sound installation, Développement d'une installation sonore et lumineuse interactive",
        "impact": null,
        "media": [
            "https://www.instagram.com/lozanohemmer/"
        ],
        "instagram": [
            "https://www.instagram.com/lozanohemmer/"
        ],
        "cover": null,
        "hasMedia": true,
        "fullDescription": "A suspended forest of 481 speaker-lights creates a living parliament where climate voices gather and disperse. Archival recordings, scientific testimonies, protest chants, and personal reflections form a chorus that responds to movement—as visitors walk through the space, they literally assemble temporary coalitions of voices around their bodies. The installation transforms abstract climate discourse into an embodied, spatial experience.\n\n**Technical details and implementation**\n- Suspended array of 481 pendant speaker-lights with integrated LED rings creating a responsive canopy\n- Thousands of curated audio clips distributed across nodes with sophisticated spatial audio processing\n- Advanced presence and motion sensing triggers localized activations and wave-propagation patterns\n- Real-time audio mixing prevents sonic chaos while maintaining spatial clarity\n\n**Challenges and solutions**\n- Preventing sonic overload required spatial mixing algorithms, dynamic range control, and per-zone prioritization\n- Managing power, data, and synchronization across hundreds of nodes demanded robust network topology and precise clocking\n- Eliminating false triggers and dead zones required carefully tuned sensor thresholds and comprehensive coverage mapping\n\n**Impact and results**\n- Transforms climate discourse from abstract to embodied—visitors physically assemble debates through movement\n- Creates a unique space for reflection and discussion in public and academic contexts\n- Demonstrates how technology can make complex social issues spatially and emotionally accessible\n\n**Process and methodology**\n- Extensive content research and rights clearance with systematic taxonomy of sources and thematic tags\n- Scale modeling and simulation of array geometry, audio density, and decay patterns\n- On-site commissioning with iterative balancing of light and sound to achieve optimal visitor experience\n\n\n---"
    },
    {
        "id": "field-atmosphonia",
        "title": "FIELD ATMOSPHONIA",
        "year": null,
        "client": "Rafael Lozano-Hemmer / Artis – Naples",
        "role": null,
        "technologies": null,
        "description": "Audio-reactive lighting, immersive sound environment, Développement d'un environnement sonore immersif",
        "impact": null,
        "media": [
            "https://www.instagram.com/lozanohemmer/"
        ],
        "instagram": [
            "https://www.instagram.com/lozanohemmer/"
        ],
        "cover": null,
        "hasMedia": true,
        "fullDescription": "An immersive sound environment where thousands of discrete audio channels create a living acoustic ecosystem. Rather than presenting a fixed composition, the space becomes an active listener—responding to presence by redistributing attention, proximity, and density across its vast sonic landscape. Visitors enter not as passive listeners but as participants in an ever-shifting atmospheric composition.\n\n**Technical details and implementation**\n- 3,000+ channel audio library distributed across multiple speakers with sophisticated spatialization\n- Interactive logic modulates density and emphasis based on real-time audience presence and movement\n- Subtle light elements serve as sonic visualizers, creating visual echoes of the audio experience\n- Advanced audio routing and content management system handles the massive channel count\n\n**Challenges and solutions**\n- Managing thousands of audio channels required distributed architecture and intelligent content management\n- Preventing perceptual muddiness demanded careful spectral curation and precise spatial separation\n- Ensuring consistent coverage across varied listening positions required extensive room-specific tuning\n\n**Impact and results**\n- Fundamentally reframes sound as environmental experience rather than performance\n- Generates prolonged dwell times and repeat visits as visitors discover new sonic relationships\n- Achieves accessibility without explicit instructions—visitors intuitively understand they're part of the mix\n\n**Process and methodology**\n- Iterative curation of recordings and textures to create rich, layered soundscapes\n- Small-array prototyping and testing before scaling to full installation\n- Room-specific equalization and delay compensation for optimal acoustic experience\n\n\n---"
    },
    {
        "id": "kristallstimmen",
        "title": "KRISTALLSTIMMEN",
        "year": null,
        "client": "Rafael Lozano-Hemmer / Swarovski Crystal Worlds",
        "role": null,
        "technologies": null,
        "description": "Interactive audio installation, Développement d'une installation audio interactive",
        "impact": null,
        "media": [
            "https://www.instagram.com/lozanohemmer/"
        ],
        "instagram": [
            "https://www.instagram.com/lozanohemmer/"
        ],
        "cover": null,
        "hasMedia": true,
        "fullDescription": "A crystalline sound chamber where voices transform into shimmering harmonics. Visitors speak into the space and hear their words returned as refracted echoes, spectral shimmers, and harmonized layers that dance through the faceted architecture. The installation transforms the room into a living instrument, where material luxury meets intimate acoustic presence.\n\n**Technical details and implementation**\n- Microphones and speakers embedded within crystal structures create seamless audio integration\n- Advanced DSP processing generates crystalline echoes, spectral shimmers, and harmonized voice layers\n- Audio-reactive lighting system responds to sound with refracted patterns across faceted elements\n- Sophisticated feedback prevention and gain staging for close-proximity audio components\n\n**Challenges and solutions**\n- Highly reflective crystal environment required targeted EQ, notch filters, and strategic absorptive treatments\n- Managing feedback risk with close microphone/speaker placement demanded precise gating, directionality, and gain staging\n- Achieving clear audio in reflective space required extensive acoustic modeling and material studies\n\n**Impact and results**\n- Creates profound sense of wonder and self-awareness as visitors discover they can 'play' the room\n- Successfully bridges luxury brand aesthetics with cutting-edge experiential media art\n- Generates extended visitor engagement as people explore the acoustic possibilities\n\n**Process and methodology**\n- Comprehensive material and acoustic studies of crystal surfaces and their reflective properties\n- Rapid DSP prototyping with extensive preset banks for tonal variety and musical exploration\n- On-site voicing and calibration with live audience testing to optimize the interactive experience\n\n\n---"
    },
    {
        "id": "shadow-tuner",
        "title": "SHADOW TUNER",
        "year": null,
        "client": "Rafael Lozano-Hemmer / Abu Dhabi",
        "role": null,
        "technologies": null,
        "description": "Interactive projection, real-time audio-reactive visuals, Développement d'une projection interactive",
        "impact": null,
        "media": [
            "https://www.instagram.com/lozanohemmer/"
        ],
        "instagram": [
            "https://www.instagram.com/lozanohemmer/"
        ],
        "cover": null,
        "hasMedia": true,
        "fullDescription": "An interactive installation where participants transform their shadows into living instruments. The absence of light becomes the source of expression—gestures cast as shadows generate sound and graphics, turning negative space into a canvas for musical and visual creation. Visitors discover they can 'tune' their shadows, creating a poetic inversion where darkness becomes the instrument of light.\n\n**Technical details and implementation**\n- Infrared capture system provides reliable silhouette detection under variable lighting conditions\n- Advanced projection mapping renders edge-tracked forms with audio-reactive fills and textures\n- Live sound synthesis engine maps gesture scale, velocity, and dwell time to musical parameters\n- Multi-projector setup with sophisticated warping and blending for seamless large-surface coverage\n\n**Challenges and solutions**\n- Detecting shadows in mixed lighting required IR isolation and sophisticated background subtraction algorithms\n- Eliminating perceptual lag demanded optimized GPU pipelines and ultra-low-latency audio processing\n- Large-surface projection mapping required multi-projector warping, blending, and geometric calibration\n\n**Impact and results**\n- Encourages playful discovery and experimentation across all age groups\n- Creates profound poetic inversion—transforming absence into presence, darkness into expression\n- Demonstrates how technology can make the invisible visible and the negative positive\n\n**Process and methodology**\n- Extensive algorithm prototyping for contour detection and edge stability across various lighting conditions\n- Participatory testing with diverse user groups to balance responsiveness with visual clarity\n- Final site calibration including projection geometry optimization and sound pressure level tuning\n\n\n---"
    },
    {
        "id": "collider",
        "title": "COLLIDER",
        "year": null,
        "client": "Rafael Lozano-Hemmer / Lulu Island",
        "role": null,
        "technologies": null,
        "description": "Real-time data visualization, cosmic radiation detection, Développement d'une visualisation en temps réel",
        "impact": null,
        "media": [
            "https://www.instagram.com/lozanohemmer/"
        ],
        "instagram": [
            "https://www.instagram.com/lozanohemmer/"
        ],
        "cover": null,
        "hasMedia": true,
        "fullDescription": "A real-time visualization of cosmic radiation events transforms invisible astrophysics into luminous collisions and particle showers. Live data from cosmic ray detectors becomes an evolving field of light that visitors can read at a glance or inhabit over time, making the constant bombardment of high-energy particles from space visible and comprehensible.\n\n**Technical details and implementation**\n- Live data feed from cosmic ray detectors captures real-time radiation events\n- Custom visualization engine maps event energy and angle to dynamic particles, trails, and bursts\n- High-resolution projection or display systems ensure clarity under ambient lighting conditions\n- Sophisticated data processing handles the stochastic nature of cosmic ray detection\n\n**Challenges and solutions**\n- Managing data dropouts and noise required robust buffering and advanced denoising strategies\n- Balancing scientific legibility with visual awe demanded a visual grammar that scales from micro to macro events\n- Creating engaging visualization from inherently random data required careful design of visual metaphors\n\n**Impact and results**\n- Connects everyday spaces with cosmic phenomena, fostering scientific curiosity across all ages\n- Successfully bridges science outreach and media art, making complex physics accessible and beautiful\n- Demonstrates how real-time data visualization can transform abstract science into visceral experience\n\n**Process and methodology**\n- Collaboration with physicists and research institutions for authentic sensor access and data validation\n- Intensive design sprints to develop visual metaphors and language for cosmic phenomena\n- In-situ tuning and calibration for optimal viewing under various ambient lighting conditions\n\n\n---"
    },
    {
        "id": "recurrent-first-dream",
        "title": "RECURRENT FIRST DREAM",
        "year": null,
        "client": "Rafael Lozano-Hemmer / ZONAMACO ARTFAIR",
        "role": null,
        "technologies": null,
        "description": "Oeuvre d'art générative",
        "impact": null,
        "media": [
            "https://www.instagram.com/lozanohemmer/"
        ],
        "instagram": [
            "https://www.instagram.com/lozanohemmer/"
        ],
        "cover": null,
        "hasMedia": true,
        "fullDescription": "A generative homage to Sor Juana Inés de la Cruz's 'Primero Sueño' that unfolds as endlessly recomposed text-image constellations. The installation creates an infinite poem where textual structures inform visual grammars, and synchronized currents of meaning diverge and reconverge across multiple screens without ever repeating. Viewers witness literature transformed into living, breathing visual code.\n\n**Technical details and implementation**\n- Custom generative engine drives multi-screen sequences that never repeat, creating infinite variations\n- Textual structures from the original poem inform graphical grammars, pacing, and visual composition\n- Four-screen synchronization system with drift-resistant clocking ensures perfect temporal alignment\n- Advanced shader optimization and frame budgeting manage GPU load across multiple displays\n\n**Challenges and solutions**\n- Avoiding perceptual repetition required massive state spaces and sophisticated stochastic pathing algorithms\n- Managing GPU load across four screens demanded shader optimization and careful frame budgeting\n- Creating meaningful visual poetry required deep understanding of both literary structure and generative systems\n\n**Impact and results**\n- Successfully bridges literature and code, making viewers sense an infinite poem made visible\n- Demonstrates versatility by working effectively in both art fair and gallery contexts\n- Creates meditative, contemplative experience that rewards extended viewing\n\n**Process and methodology**\n- Extensive poetic research with motif and semantic mapping to understand the original text's structure\n- Parameter studies to balance legibility with abstraction, ensuring the work remains accessible\n- Rigorous rack-level testing for multi-screen synchronization and technical reliability\n\n\n---"
    },
    {
        "id": "translation-island",
        "title": "TRANSLATION ISLAND",
        "year": null,
        "client": "Rafael Lozano-Hemmer / ABU DHABI",
        "role": null,
        "technologies": null,
        "description": "Parcours d'art en extérieur",
        "impact": null,
        "media": [
            "https://www.instagram.com/lozanohemmer/"
        ],
        "instagram": [
            "https://www.instagram.com/lozanohemmer/"
        ],
        "cover": null,
        "hasMedia": true,
        "fullDescription": "A public art trail in Abu Dhabi that stages translation as wayfinding—light, text, and sound guide visitors through sequential ‘islands’ of narrative across an outdoor landscape.\n\nTechnical details and implementation\n- Weatherproof projection/lighting integrated with site features.\n- Sensors along the path to pace narrative reveals.\n- Multilingual text and audio assets for inclusive access.\n\nChallenges and solutions\n- Harsh outdoor conditions → sealed housings, high‑lumen projectors, scheduled maintenance.\n- Crowd flow → distributed triggers and clear path sightlines.\n\nImpact and results\n- Turns public space into a participatory story; invites repeat walks to catch different timings.\n- Signals the city’s commitment to cultural programming.\n\nProcess and methodology\n- Site survey and storyboarding per waypoint.\n- Modular rigging and power planning.\n- Night‑time calibration runs in situ.\n\n\n---"
    },
    {
        "id": "atmospheric-memory",
        "title": "ATMOSPHERIC MEMORY",
        "year": null,
        "client": "Rafael Lozano-Hemmer / Sydney",
        "role": null,
        "technologies": null,
        "description": "Exposition immersive",
        "impact": null,
        "media": [
            "https://www.instagram.com/ey_global/"
        ],
        "instagram": [
            "https://www.instagram.com/ey_global/"
        ],
        "cover": null,
        "hasMedia": true,
        "fullDescription": "A touring large-scale exhibition inspired by Charles Babbage's visionary speculation that the air retains every word ever spoken. Multiple rooms of voice-activated projections, robotics, and sonification transform atmosphere into both archive and instrument, creating an immersive exploration of memory, surveillance, and the persistence of sound in space.\n\n**Technical details and implementation**\n- Multiple interconnected rooms combining projection, robotics, multi-channel sound, and interactive voice capture\n- Voice input drives complex text, visual, and kinetic responses across different media systems\n- Sophisticated touring adaptations accommodate varied venue sizes and architectural constraints\n- Modular room design allows flexible configuration for different exhibition contexts\n\n**Challenges and solutions**\n- Complex systems integration across multiple media types required modular room design and robust show control\n- Ensuring accessibility and clear onboarding demanded intuitive affordances and comprehensive staff training\n- Managing touring logistics required standardized installation procedures and efficient strike protocols\n\n**Impact and results**\n- Connects historical computing concepts to contemporary anxieties around memory, privacy, and surveillance\n- Generated significant public engagement and critical discourse in art and technology communities\n- Successfully toured multiple venues, demonstrating the work's adaptability and lasting relevance\n\n**Process and methodology**\n- Extensive historical research into Babbage's work and its contemporary implications\n- Room-by-room prototyping and playtesting to optimize user experience and technical reliability\n- Development of comprehensive touring playbooks for efficient installation and strike procedures\n\n\n---"
    },
    {
        "id": "sync",
        "title": "SYNC",
        "year": null,
        "client": "Rafael Lozano-Hemmer / SAN FRANCISCO",
        "role": null,
        "technologies": null,
        "description": "Performance audio réactive",
        "impact": null,
        "media": [
            "https://www.instagram.com/lozanohemmer/"
        ],
        "instagram": [
            "https://www.instagram.com/lozanohemmer/"
        ],
        "cover": null,
        "hasMedia": true,
        "fullDescription": "A live performance collaboration with percussionist Eli Keszler, presented in San Francisco and at Pace Gallery (New York). Using Sensory Percussion, the drum kit becomes a controller for light and image—each strike, scrape and resonance extends into synchronized projection.\n\nTechnical details and implementation\n- Sensory Percussion mapped to OSC/MIDI controlling projection and lighting.\n- TouchDesigner/real‑time pipeline tuned for sub‑frame responsiveness.\n- Adaptations for white‑cube (Pace) and stage contexts (San Francisco).\n\nChallenges and solutions\n- Capturing micro‑gestures without visual overload → scaled mappings and soft thresholds.\n- Latency management → direct device routing and GPU prioritization.\n- Rapid venue re‑calibration between radically different spaces.\n\nImpact and results\n- Reframed percussion as multi‑sensory practice; strong audience immersion.\n- Documented templates reused in later performance projects.\n\nProcess and methodology\n- Mapping rehearsals with performer to ‘play’ the visuals.\n- Preset banks for different pieces; live tweak panel for operator.\n- Tear‑down/bring‑up checklists per venue.\n\n\n---"
    },
    {
        "id": "a-generative-movement",
        "title": "A GENERATIVE MOVEMENT",
        "year": null,
        "client": "Rafael Lozano-Hemmer & bitforms gallery / SAN FRANCISCO",
        "role": null,
        "technologies": null,
        "description": "Exposition solo",
        "impact": null,
        "media": [
            "https://www.instagram.com/bitforms/"
        ],
        "instagram": [
            "https://www.instagram.com/bitforms/"
        ],
        "cover": null,
        "hasMedia": false
    },
    {
        "id": "techs-mechs",
        "title": "TECHS MECHS",
        "year": null,
        "client": "Rafael Lozano-Hemmer & Gray Area / SAN FRANCISCO",
        "role": null,
        "technologies": null,
        "description": "Exposition solo",
        "impact": null,
        "media": [
            "https://www.instagram.com/grayareaorg/"
        ],
        "instagram": [
            "https://www.instagram.com/grayareaorg/"
        ],
        "cover": null,
        "hasMedia": true,
        "fullDescription": "A solo exhibition at Gray Area (San Francisco) that foregrounded three contributions: Airborne Newscast (dual‑projector shadow tracking that projects around/inside), a four‑screen Recurrent First Dream, and a Thermal Drift Density Map experiment.\n\nTechnical details and implementation\n- Airborne Newscast: two mapped projectors; live shadow tracking and projection.\n- Recurrent First Dream: synced 4‑screen generative choreography.\n- Thermal Drift Density Map: heat‑field into density visualization; new render path.\n\nChallenges and solutions\n- Dual projector blending and shadow occlusion management.\n- GPU tuning for multi‑screen stability.\n- Thermal denoising and stability under gallery traffic.\n\nImpact and results\n- Showed breadth from tracking to generative poetics; strong institutional interest.\n- Laid technical groundwork for subsequent installations.\n\nProcess and methodology\n- Piece‑by‑piece prototyping; common show control backbone.\n- On‑site alignment and visitor‑flow tuning.\n- Post‑show documentation for redeployment.\n\n\n---"
    },
    {
        "id": "biometric-theatre",
        "title": "BIOMETRIC THEATRE",
        "year": null,
        "client": "Rafael Lozano-Hemmer / HONG KONG",
        "role": null,
        "technologies": null,
        "description": "Exposition solo",
        "impact": null,
        "media": [
            "https://www.instagram.com/lozanohemmer/"
        ],
        "instagram": [
            "https://www.instagram.com/lozanohemmer/"
        ],
        "cover": null,
        "hasMedia": true,
        "fullDescription": "An immersive environment in Hong Kong where audience physiology drives media. A monumental Thermal Drift projection visualizes collective heat, while a large Hormonium projection renders cyclical rhythms at architectural scale.\n\nTechnical details and implementation\n- Heartbeat/respiration/thermal sensing; anonymized, aggregate mappings.\n- Large Thermal Drift projection; large Hormonium projection.\n- Sound design tied to biometric tempo envelopes.\n\nChallenges and solutions\n- Scaling biometric input to crowd contexts without noise or privacy issues.\n- Architectural projection clarity under variable ambient light.\n\nImpact and results\n- Made inner states shareable; strong public curiosity and participation.\n- Advanced discourse around data ethics in art contexts.\n\nProcess and methodology\n- Sensor calibration for groups; consent/onboarding UI.\n- Mapping workshops to keep outputs legible and meaningful.\n- Live ops playbook to maintain stability through peak hours.\n\n\n---"
    },
    {
        "id": "thermal-drift",
        "title": "THERMAL DRIFT",
        "year": null,
        "client": "Rafael Lozano-Hemmer / NYC ARMORY ARTFAIR",
        "role": null,
        "technologies": null,
        "description": "Oeuvre d'art interactive",
        "impact": null,
        "media": [
            "https://www.instagram.com/lozanohemmer/"
        ],
        "instagram": [
            "https://www.instagram.com/lozanohemmer/"
        ],
        "cover": null,
        "hasMedia": true,
        "fullDescription": "An interactive thermal camera installation where human bodies emit particles that drift and dissolve along a six-minute narrative arc. This cornerstone work transforms invisible body heat into visible poetry, creating an intimate dance between technology and human presence that has been exhibited worldwide and collected in multiple editions.\n\n**Technical details and implementation**\n- High-sensitivity thermal camera with sophisticated calibrated background profiling\n- Custom particle shader system with audio-reactive modulation controlling density and flow patterns\n- Comprehensive editioning pipeline optimized for gallery and art fair deployment\n- Advanced background subtraction algorithms maintain visual contrast across diverse installation sites\n\n**Challenges and solutions**\n- Maintaining visual contrast across different sites required adaptive background subtraction and environmental calibration\n- Handling high visitor throughput demanded particle pooling, culling algorithms, and dynamic resolution scaling\n- Creating consistent experience across venues required flexible adaptation for various screen and projection setups\n\n**Impact and results**\n- Exhibited at prestigious venues including NYC Armory Art Fair, Basel 2022, and Crystal Bridges' Listening Forest\n- Multiple editions sold to private and institutional collections worldwide\n- Established as a signature work that demonstrates the poetic potential of thermal imaging technology\n\n**Process and methodology**\n- Iterative prototyping with various thermal sensors and lens configurations to optimize image quality\n- Careful narrative curve design that guides viewers from abstraction to figuration over six minutes\n- Per-site adaptation protocols for different display technologies and visitor traffic patterns\n\n\n---"
    },
    {
        "id": "listening-forest",
        "title": "LISTENING FOREST",
        "year": null,
        "client": "Rafael Lozano-Hemmer / CRYSTAL BRIDGES MUSEUM - ARKANSAS",
        "role": null,
        "technologies": null,
        "description": "Parcours d'art en extérieur",
        "impact": null,
        "media": [
            "https://www.instagram.com/crystalbridgesmuseum/"
        ],
        "instagram": [
            "https://www.instagram.com/crystalbridgesmuseum/"
        ],
        "cover": null,
        "hasMedia": true,
        "fullDescription": "A night‑time forest trail at Crystal Bridges (Arkansas) featuring distributed interactive artworks. Contributions included Arkansas Text Stream, an outdoor adaptation of Thermal Drift, and Summon—each transforming the woods into a responsive commons.\n\nTechnical details and implementation\n- Distributed projection/lights and sensing along a long outdoor path.\n- Arkansas Text Stream; Thermal Drift (outdoor); Summon as collective response node.\n\nChallenges and solutions\n- Weatherproofing and reliable power/data runs over distance.\n- Designing for wayfinding and safety while preserving mystery.\n\nImpact and results\n- Major public draw; broadened the museum’s audience profile.\n- Model for blending landscape and media art.\n\nProcess and methodology\n- Trail survey and node planning; cable/power routing.\n- Outdoor calibration at night; maintenance cycles.\n- Visitor‑flow tests to avoid bottlenecks.\n\n\n---"
    },
    {
        "id": "excuse-you",
        "title": "EXCUSE YOU",
        "year": null,
        "client": "Rafael Lozano-Hemmer & Wilde Gallery / BASEL",
        "role": null,
        "technologies": null,
        "description": "Exposition solo",
        "impact": null,
        "media": [
            "https://www.instagram.com/lozanohemmer/"
        ],
        "instagram": [
            "https://www.instagram.com/lozanohemmer/"
        ],
        "cover": null,
        "hasMedia": true,
        "fullDescription": "A solo show at Wilde (Basel) that consolidated several works into a gallery context. Production included a Thermal Drift Density Map, a presentation of Hormonium, and an adapted Parametric Staircase—focusing on installation craft and cohesion.\n\nTechnical details and implementation\n- Gallery‑scale Thermal Drift Density Map variant.\n- Hormonium projection install; Parametric Staircase adaptation.\n- Unified show control and monitoring.\n\nChallenges and solutions\n- Time‑boxed installation with diverse technical needs.\n- Maintaining coherence across heterogeneous works.\n\nImpact and results\n- Strengthened gallery relationships and collector interest.\n- Demonstrated production capabilities for complex multi‑work shows.\n\nProcess and methodology\n- Advance planning with detailed floor plan and IO map.\n- On‑site adjustments for scale and viewing distances.\n- Post‑install testing under opening‑night conditions.\n\n\n---"
    },
    {
        "id": "haciendo-agua",
        "title": "HACIENDO AGUA",
        "year": null,
        "client": "Rafael Lozano-Hemmer & Max Estrella Gallery / MADRID",
        "role": null,
        "technologies": null,
        "description": "Exposition solo",
        "impact": null,
        "media": [
            "https://www.instagram.com/lozanohemmer/"
        ],
        "instagram": [
            "https://www.instagram.com/lozanohemmer/"
        ],
        "cover": null,
        "hasMedia": false
    },
    {
        "id": "caudales",
        "title": "CAUDALES",
        "year": null,
        "client": "Rafael Lozano-Hemmer / MADRID CASA DE MEXICO",
        "role": null,
        "technologies": null,
        "description": "Exposition d'oeuvres génératives et interactives",
        "impact": null,
        "media": [
            "https://www.instagram.com/casademexicoenespana/"
        ],
        "instagram": [
            "https://www.instagram.com/casademexicoenespana/"
        ],
        "cover": null,
        "hasMedia": true,
        "fullDescription": "An exhibition at Casa de Mexico (Madrid) organized around flows and circulation. Contributions spanned Airborne Newscast, Recurrent Rayuela, Sor Juana Chandelier, installations of Encode/Decode and Mallarmé, and a presentation of Hormonium.\n\nTechnical details and implementation\n\nDual‑projector tracking (Airborne Newscast); kinetic/light components (Chandelier).Installation of Encode/Decode and Mallarmé; Hormonium display.Challenges and solutions\n\nIntegrating technically diverse works into one dramaturgy.International install logistics and coordination.Impact and results\n\nCreated a dense, multi‑modal experience anchoring literary references.Expanded institutional network in Spain.Process and methodology\n\nPiece‑specific prebuilds; crate/ship documentation.On‑site sequencing and light levels per room.Handover docs for local technicians.---"
    },
    {
        "id": "hormonium",
        "title": "HORMONIUM",
        "year": null,
        "client": "Rafael Lozano-Hemmer / MADRID",
        "role": null,
        "technologies": null,
        "description": "Oeuvre d'art générative",
        "impact": null,
        "media": [
            "https://www.instagram.com/lozanohemmer/"
        ],
        "instagram": [
            "https://www.instagram.com/lozanohemmer/"
        ],
        "cover": null,
        "hasMedia": true,
        "fullDescription": "A generative visual of cyclical ‘biological’ rhythms. Over the years it has proven highly adaptable—shown in multiple exhibitions and acquired by collections, evolving across formats without losing identity.\n\nTechnical details and implementation\n- Cyclical waveform engines with parameterized phase/period relationships.\n- Projection mapping or screen presentation; ambient or focal modes.\n\nChallenges and solutions\n- Keeping long‑run interest → slow evolution with punctuated ‘events’.\n- Scaling from intimate to architectural surfaces.\n\nImpact and results\n- Exhibited internationally and sold in multiple editions over several years.\n- Frequently requested due to its formal clarity and atmospheric depth.\n\nProcess and methodology\n- Ongoing code refinements and palette libraries.\n- Per‑venue pacing presets and brightness profiles.\n\n\n---"
    },
    {
        "id": "lcs-opening-ceremony",
        "title": "LCS OPENING CEREMONY",
        "year": null,
        "client": "Moment Factory / LOS ANGELES",
        "role": null,
        "technologies": null,
        "description": "Réalité augmentée en direct",
        "impact": null,
        "media": [
            "https://www.instagram.com/lolesports/"
        ],
        "instagram": [
            "https://www.instagram.com/lolesports/"
        ],
        "cover": null,
        "hasMedia": false
    },
    {
        "id": "ecosystemes",
        "title": "ECOSYSTEMES",
        "year": null,
        "client": "MAPP MTL - Aude Guivarch / MONTREAL",
        "role": null,
        "technologies": null,
        "description": "Mapping",
        "impact": null,
        "media": [
            "https://www.instagram.com/audemaeva/"
        ],
        "instagram": [
            "https://www.instagram.com/audemaeva/"
        ],
        "cover": null,
        "hasMedia": true,
        "fullDescription": "A projection mapping work (with Aude Guivarch) for MAPP MTL that turns city facades into living ecologies. Rather than listing features, the project unfolds like urban weather—growth, decay and regeneration written onto architecture so passersby can feel cyclical time in a single evening. Irregular surfaces and city light became collaborators; the map gives buildings a pulse.\n\nTechnical details and implementation\n- Large‑format projection mapping onto irregular facades.\n- Visual sequences composed as ecological cycles; adaptive brightness for urban light.\n\nChallenges and solutions\n- Facade irregularity and ambient light → detailed mesh scans and luminance compensation.\n- Maintaining legibility from varied street vantage points.\n\nImpact and results\n- Activated public space for broad audiences; approachable yet conceptually grounded.\n- Advanced the festival’s discourse on mapping as civic storytelling.\n\nProcess and methodology\n- On‑site scans and tests to author content to the surface.\n- Evening‑by‑evening tweaks as conditions changed.\n\n\n---"
    },
    {
        "id": "animistic-imagery",
        "title": "ANIMISTIC IMAGERY",
        "year": null,
        "client": "Moment Factory / BEIJING",
        "role": null,
        "technologies": null,
        "description": "Déambulatoire interactif",
        "impact": null,
        "media": [
            "https://www.instagram.com/momentfactory/"
        ],
        "instagram": [
            "https://www.instagram.com/momentfactory/"
        ],
        "cover": null,
        "hasMedia": true,
        "fullDescription": "A walk‑through installation in Beijing reimagining animistic traditions through digital media. Entirely developed **remotely**, with no on‑site testing—demanding precise simulation, documentation, and trust with local teams.\n\nTechnical details and implementation\n- Multi‑room projections and soundscapes; motion‑driven narrative triggers.\n- Remote production pipelines; delivery of calibrated presets and layouts.\n\nChallenges and solutions\n- Reliability without onsite iteration → comprehensive simulation and redundancy.\n- Cultural sensitivity while abstracting motifs → advisory and review loops.\n\nImpact and results\n- Successful large‑scale deployment despite distance; strong public response.\n- Exemplar of remote‑first production methodology.\n\nProcess and methodology\n- Tight spec docs, screen maps, and IO diagrams.\n- Async QA with local integrators; contingency fallback states.\n\n\n---"
    },
    {
        "id": "my-morning-jacket-album-launch",
        "title": "MY MORNING JACKET ALBUM LAUNCH",
        "year": null,
        "client": "Moment Factory / DIFFUSION WEB",
        "role": null,
        "technologies": null,
        "description": "Création de contenu",
        "impact": null,
        "media": [
            "https://www.instagram.com/mymorningjacket/"
        ],
        "instagram": [
            "https://www.instagram.com/mymorningjacket/"
        ],
        "cover": null,
        "hasMedia": false
    },
    {
        "id": "billie-eilish-2020-world-tour",
        "title": "BILLIE EILISH 2020 WORLD TOUR",
        "year": null,
        "client": "Moment Factory / WORLD",
        "role": null,
        "technologies": null,
        "description": "Création de contenu temps réel",
        "impact": null,
        "media": [
            "https://www.instagram.com/billieeilish/"
        ],
        "instagram": [
            "https://www.instagram.com/billieeilish/"
        ],
        "cover": null,
        "hasMedia": true,
        "fullDescription": "Arena‑scale generative visuals built with **Notch** and **Disguise**, developed in collaboration with the lighting designer, video team and live video operator. The system emphasized real‑time flexibility to meet the artist’s dynamic performance.\n\nTechnical details and implementation\n- Notch real‑time effects pipeline; Disguise media servers.\n- Timecode and live operator control for adaptive moments.\n- Integration with lighting cues and camera feeds.\n\nChallenges and solutions\n- Consistency across venues with different LED inventories → modular scene graphs.\n- Keeping energy aligned with performance while avoiding visual fatigue.\n\nImpact and results\n- Delivered a cohesive high‑impact visual identity for a global pop tour.\n- Showcased robustness of real‑time pipelines in stadium contexts.\n\nProcess and methodology\n- Rehearsal‑driven mapping from musical structure to visual behavior.\n- Operator playbooks for show‑by‑show tweaks.\n\n\n---"
    },
    {
        "id": "panasonic-augmented-basketball-court",
        "title": "PANASONIC AUGMENTED BASKETBALL COURT",
        "year": null,
        "client": "Moment Factory / MONTRÉAL",
        "role": null,
        "technologies": null,
        "description": "R&D",
        "impact": null,
        "media": [
            "https://www.instagram.com/momentfactory/"
        ],
        "instagram": [
            "https://www.instagram.com/momentfactory/"
        ],
        "cover": null,
        "hasMedia": true,
        "fullDescription": "A projection-mapped basketball court that tracks players and the ball in real-time, overlaying responsive graphics directly onto gameplay. This R&D project originated in Montreal and **led directly to an NBA contract**, demonstrating how experimental media art can evolve into practical applications that transform professional sports.\n\n**Technical details and implementation**\n- High-speed projection system with ultra-low-latency tracking of players and ball movement\n- Sophisticated camera/projector calibration system ensures perfect alignment with court geometry\n- Robust anti-glare strategies and high-lumen projection for visibility under intense gym lighting\n- Real-time gameplay overlays that respond to player actions and game dynamics\n\n**Challenges and solutions**\n- Achieving ultra-low latency required optimized tracking pipelines and predictive algorithms\n- Maintaining visibility under harsh gym lighting demanded high-lumen projection and careful surface preparation\n- Creating reliable tracking in dynamic sports environment required advanced computer vision and machine learning\n\n**Impact and results**\n- Prototype successfully proved value to professional sports partner, leading to NBA contract\n- Opened new pathways for augmented reality in training and fan experiences\n- Demonstrated how experimental media art can evolve into practical commercial applications\n\n**Process and methodology**\n- Closed-loop testing with professional athletes to optimize tracking accuracy and overlay timing\n- Iterative development of overlay rules and visual feedback systems\n- Comprehensive resiliency testing for sweat, dust, and frequent play conditions\n\n\n---"
    },
    {
        "id": "ocean-park-illumination",
        "title": "OCEAN PARK ILLUMINATION",
        "year": null,
        "client": "Moment Factory / HONG KONG",
        "role": null,
        "technologies": null,
        "description": "Installation interactive",
        "impact": null,
        "media": [
            "https://www.instagram.com/hkoceanpark/"
        ],
        "instagram": [
            "https://www.instagram.com/hkoceanpark/"
        ],
        "cover": null,
        "hasMedia": false
    },
    {
        "id": "avett-brothers-tour",
        "title": "AVETT BROTHERS TOUR",
        "year": null,
        "client": "Moment Factory /",
        "role": null,
        "technologies": null,
        "description": "Création de contenu",
        "impact": null,
        "media": [
            "https://www.instagram.com/theavettbrothers/"
        ],
        "instagram": [
            "https://www.instagram.com/theavettbrothers/"
        ],
        "cover": null,
        "hasMedia": true,
        "fullDescription": "Concert visuals combining precomposed motion design with real‑time elements. A flexible package traveled well, complementing the band’s narrative‑driven sets without overwhelming them.\n\nTechnical details and implementation\n- LED wall content plus live camera treatments.\n- Timing strategies for variable setlists; per‑song looks.\n\nChallenges and solutions\n- Venue variability → scalable layouts and per‑load‑in checks.\n- Maintaining emotional tone alongside storytelling songs.\n\nImpact and results\n- Enhanced audience immersion while preserving focus on performers.\n- Demonstrated tour‑ready reliability of the media package.\n\nProcess and methodology\n- Rehearsal capture -> look development -> show files.\n- Operator notes per venue; quick‑switch scene banks.\n\n\n---"
    },
    {
        "id": "halsey-world-tour",
        "title": "HALSEY WORLD TOUR",
        "year": null,
        "client": "Moment Factory / LOS ANGELES",
        "role": null,
        "technologies": null,
        "description": "Création de contenu",
        "impact": null,
        "media": [
            "https://www.instagram.com/iamhalsey/"
        ],
        "instagram": [
            "https://www.instagram.com/iamhalsey/"
        ],
        "cover": null,
        "hasMedia": false
    },
    {
        "id": "breathless-london-art-now",
        "title": "BREATHLESS : LONDON ART NOW",
        "year": null,
        "client": "Ca' Pesaro Galleria Internazionale d'Arte Moderna & Ed Fornieles / VENEZIA",
        "role": null,
        "technologies": null,
        "description": "Programmation Unity et intégration",
        "impact": null,
        "media": [],
        "instagram": [],
        "cover": null,
        "hasMedia": false
    },
    {
        "id": "hines-louisiana",
        "title": "HINES LOUISIANA",
        "year": null,
        "client": "Float4 / MONTRÉAL-HOUSTON",
        "role": null,
        "technologies": null,
        "description": "Contenu génératif",
        "impact": null,
        "media": [],
        "instagram": [],
        "cover": null,
        "hasMedia": false
    },
    {
        "id": "rock-in-rio",
        "title": "ROCK IN RIO",
        "year": null,
        "client": "Moment Factory / MONTRÉAL-RIO",
        "role": null,
        "technologies": null,
        "description": "Mapping + Tracking en temps réel",
        "impact": null,
        "media": [
            "https://www.instagram.com/momentfactory/"
        ],
        "instagram": [
            "https://www.instagram.com/momentfactory/"
        ],
        "cover": null,
        "hasMedia": false
    },
    {
        "id": "halte-00-îles-de-boucherville",
        "title": "HALTE 00 ÎLES-DE-BOUCHERVILLE",
        "year": null,
        "client": "SÉPAQ / MONTRÉAL",
        "role": null,
        "technologies": null,
        "description": "Architecture + Interactivité",
        "impact": null,
        "media": [],
        "instagram": [],
        "cover": null,
        "hasMedia": false
    },
    {
        "id": "d-vernissage-calder",
        "title": "D-VERNISSAGE CALDER",
        "year": null,
        "client": "Musée des Beaux-Arts / MONTRÉAL",
        "role": null,
        "technologies": null,
        "description": "Installation laser/lumière",
        "impact": null,
        "media": [],
        "instagram": [],
        "cover": null,
        "hasMedia": false
    },
    {
        "id": "le-choeur-de-géants",
        "title": "LE CHOEUR DE GÉANTS",
        "year": null,
        "client": "Les Univers Givrés / SHAWINIGAN",
        "role": null,
        "technologies": null,
        "description": "Installation interactive",
        "impact": null,
        "media": [],
        "instagram": [],
        "cover": null,
        "hasMedia": false
    },
    {
        "id": "dead-obies-doo-wop",
        "title": "DEAD OBIES DOO WOP",
        "year": null,
        "client": "Telescope Production / MONTRÉAL",
        "role": null,
        "technologies": null,
        "description": "Performance laser",
        "impact": null,
        "media": [
            "https://www.instagram.com/deadobies/"
        ],
        "instagram": [
            "https://www.instagram.com/deadobies/"
        ],
        "cover": null,
        "hasMedia": true,
        "fullDescription": "A **music video** (not a live show) for the Montreal hip hop group. Laser programming was built directly for camera—no rehearsals, just precise cueing to the recorded track and lighting for the lens.\n\nTechnical details and implementation\n- Laser programming tailored to cinematography and shutter angles.\n- Tight sync to master audio; compositing considerations in post.\n\nChallenges and solutions\n- Safety and exposure control in close quarters with lasers.\n- Balancing smoke/haze density for beam visibility on camera.\n\nImpact and results\n- Delivered a sharp visual identity for the single; widely shared among fans.\n- Demonstrated laser aesthetics within video production constraints.\n\nProcess and methodology\n- Pre‑program cues and camera tests.\n- On‑shoot adjustments; post‑grade passes to seat the beams.\n\n\n---"
    },
    {
        "id": "rymz-gta",
        "title": "RYMZ GTA",
        "year": null,
        "client": "Joy Ride Records / MONTREAL",
        "role": null,
        "technologies": null,
        "description": "Set-Design",
        "impact": null,
        "media": [],
        "instagram": [],
        "cover": null,
        "hasMedia": false
    },
    {
        "id": "refractions",
        "title": "REFRACTIONS",
        "year": null,
        "client": "Galerie Never Apart / MONTRÉAL - TORONTO",
        "role": null,
        "technologies": null,
        "description": "Oeuvre laser",
        "impact": null,
        "media": [],
        "instagram": [],
        "cover": null,
        "hasMedia": true,
        "fullDescription": "A laser‑based light sculpture that treats beams as tangible volumes. With haze and precise optics, geometry becomes architecture, asking viewers to walk and align their perspective to ‘slice’ light.\n\nTechnical details and implementation\n- Multi‑laser rig with controlled scan patterns; safety interlocks.\n- Haze/atmospheric management to reveal volumes.\n\nChallenges and solutions\n- Alignment precision over time → rigid mounts and warm‑up protocols.\n- Audience safety in close‑range contexts → tested sightlines and barriers.\n\nImpact and results\n- Produced meditative, contemplative viewing; strong photographic documentation.\n- Expanded the studio’s vocabulary in pure light form.\n\nProcess and methodology\n- Optical tests for beam spread and reflection.\n- On‑site rehearsal of pacing and dimming curves.\n\n\n---"
    },
    {
        "id": "d-s-destiny",
        "title": "D.S DESTINY",
        "year": null,
        "client": "Moment Factory / NEW-YORK",
        "role": null,
        "technologies": null,
        "description": "Custom photobooth and game development",
        "impact": null,
        "media": [
            "https://www.instagram.com/momentfactory/"
        ],
        "instagram": [
            "https://www.instagram.com/momentfactory/"
        ],
        "cover": null,
        "hasMedia": false
    },
    {
        "id": "festival-mode-design",
        "title": "FESTIVAL MODE & DESIGN",
        "year": null,
        "client": "Vincent d'Amérique / MONTRÉAL",
        "role": null,
        "technologies": null,
        "description": "Live generative visuals",
        "impact": null,
        "media": [
            "https://www.instagram.com/madfestivalofficiel/"
        ],
        "instagram": [
            "https://www.instagram.com/madfestivalofficiel/"
        ],
        "cover": null,
        "hasMedia": false
    },
    {
        "id": "colors-of-bangkok",
        "title": "COLORS OF BANGKOK",
        "year": null,
        "client": "Moment Factory / BANGKOK",
        "role": null,
        "technologies": null,
        "description": "Visuel en temps réel",
        "impact": null,
        "media": [
            "https://www.instagram.com/momentfactory/"
        ],
        "instagram": [
            "https://www.instagram.com/momentfactory/"
        ],
        "cover": null,
        "hasMedia": true,
        "fullDescription": "An experiment fusing studio shoots with real‑time overlays. We used feedback‑style effects on fast‑moving dancers to amplify gesture across a long, horizontal canvas—tuning parameters live during recording.\n\nTechnical details and implementation\n- TouchDesigner‑based overlays blended with filmed footage in studio.\n- Real‑time parameter control to react to choreography.\n- Wide‑format composition for panoramic canvas.\n\nChallenges and solutions\n- Motion smear vs. clarity → controlled shutter and effect thresholds.\n- GPU performance under layered feedback → frame‑budget profiling.\n\nImpact and results\n- Created a kinetic hybrid image that celebrated movement.\n- Strengthened collaboration between recording and creative‑coding teams.\n\nProcess and methodology\n- On‑set experiments with dancers; immediate playback for decisions.\n- Export/LUT workflows to match post‑production look.\n\n\n---"
    },
    {
        "id": "ed-fornieles-the-finiliar",
        "title": "ED FORNIELES' THE FINILIAR",
        "year": null,
        "client": "Rosenkranz Foundation / NEW-YORK",
        "role": null,
        "technologies": null,
        "description": "Visualisation de données",
        "impact": null,
        "media": [
            "https://www.instagram.com/eddfornieles/"
        ],
        "instagram": [
            "https://www.instagram.com/eddfornieles/"
        ],
        "cover": null,
        "hasMedia": true,
        "fullDescription": "Artist Ed Fornieles created an universe in which cute creatures called Finiliar evolves emotionally. As different currencies and stocks lose and gain values over short and long period of time, the Finiliar becomes sick or happy according to the market. I've developped a system fetching different cryptocurrency values, currency values and stock values to feed the creatures in realtime."
    },
    {
        "id": "sound-tracer",
        "title": "SOUND TRACER",
        "year": null,
        "client": "Moment Factory / NEW YORK",
        "role": null,
        "technologies": null,
        "description": "Audiovisual instrument for kids",
        "impact": null,
        "media": [
            "https://www.instagram.com/momentfactory/"
        ],
        "instagram": [
            "https://www.instagram.com/momentfactory/"
        ],
        "cover": null,
        "hasMedia": true,
        "fullDescription": "An interactive instrument for kids: draw with sound and light. Gestures leave luminous traces while speakers sing back, inviting collaborative play.\n\nTechnical details and implementation\n- Large touch/gesture surface; vision tracking to strokes.\n- Real‑time sound synthesis; projection/display for drawn paths.\n\nChallenges and solutions\n- Durability for continuous public use.\n- Simplicity of interface so kids grasp it instantly.\n\nImpact and results\n- High engagement and repeat play; accessible to non‑readers.\n- Encouraged group creativity and listening.\n\nProcess and methodology\n- User testing with children; simplified affordances.\n- Ruggedized components and maintainability planning.\n\n\n---"
    },
    {
        "id": "renault-annual-meeting",
        "title": "RENAULT ANNUAL MEETING",
        "year": null,
        "client": "Moment Factory / PARIS",
        "role": null,
        "technologies": null,
        "description": "Capture de mouvement + Visuel en temps réel",
        "impact": null,
        "media": [
            "https://www.instagram.com/renaultgroup/"
        ],
        "instagram": [
            "https://www.instagram.com/renaultgroup/"
        ],
        "cover": null,
        "hasMedia": true,
        "fullDescription": "A corporate stage piece where motion capture drove real‑time visuals during the brand’s annual gathering—bringing R&D stagecraft to a formal setting without losing clarity.\n\nTechnical details and implementation\n- Live mocap pipeline mapped to generative visuals.\n- Integration with presenter cues and show caller.\n\nChallenges and solutions\n- Zero‑tolerance for downtime → redundant paths and strict show control.\n- Balancing spectacle with corporate messaging.\n\nImpact and results\n- Raised production bar for corporate events.\n- Served as a case study for hybrid art/brand performances.\n\nProcess and methodology\n- Rehearsals to align messaging and beats.\n- Failover rehearsals; clean cue sheets and comms.\n\n\n---"
    },
    {
        "id": "arcade-fire-infinite-content-tour",
        "title": "ARCADE FIRE INFINITE CONTENT TOUR",
        "year": null,
        "client": "Moment Factory / WORLD",
        "role": null,
        "technologies": null,
        "description": "Système de contrôle + visuel en temps réel",
        "impact": null,
        "media": [
            "https://www.instagram.com/arcadefire/"
        ],
        "instagram": [
            "https://www.instagram.com/arcadefire/"
        ],
        "cover": null,
        "hasMedia": true,
        "fullDescription": "A touring system centered on **four LED walls** (not 360° projection). We produced complex live‑feed effects that transformed camera captures into layered graphics and integrated them with motion design for high‑energy moments.\n\nTechnical details and implementation\n- Live camera ingest → real‑time transforms → LED walls.\n- Look library blending generative treatments with designed assets.\n\nChallenges and solutions\n- Syncing multi‑wall content without visual drift.\n- Balancing spectacle with readability for fans all around the venue.\n\nImpact and results\n- Became a benchmark for live‑feed + motion design integration in arena shows.\n- Scalable across venues with different LED specs.\n\nProcess and methodology\n- Rehearsal captures to tune effect thresholds.\n- Operator macros for quick state changes during songs.\n\n\n---"
    },
    {
        "id": "kontinuum",
        "title": "KONTINUUM",
        "year": null,
        "client": "Moment Factory / OTTAWA",
        "role": null,
        "technologies": null,
        "description": "Parcours immersif et installations interactives",
        "impact": null,
        "media": [
            "https://www.instagram.com/momentfactory/"
        ],
        "instagram": [
            "https://www.instagram.com/momentfactory/"
        ],
        "cover": null,
        "hasMedia": true,
        "fullDescription": "Before Ottawa's light-rail tunnel opened to commuters, it became a kilometer-long media environment where visitors walked through sound, light, and projection. This ambitious project reframed urban infrastructure as a cultural experience, transforming a functional transportation corridor into a temporary art installation that engaged hundreds of thousands of people.\n\n**Technical details and implementation**\n- Large-span projection mapping system covering kilometer-long tunnel walls with synchronized content\n- Distributed audio system creating immersive soundscapes throughout the tunnel length\n- Advanced sensing technology for timed activations that respond to crowd movement and density\n- Sophisticated synchronization systems maintaining perfect timing across the entire tunnel length\n\n**Challenges and solutions**\n- Ensuring safety and proper egress in underground space required close coordination with city engineers\n- Maintaining synchronization and brightness over kilometer distances demanded robust technical infrastructure\n- Creating engaging experience in challenging underground environment required innovative design solutions\n\n**Impact and results**\n- Engaged hundreds of thousands of visitors, generating significant press coverage for civic imagination\n- Established model for pre-opening cultural activation of major infrastructure projects\n- Demonstrated how temporary art installations can transform public perception of urban infrastructure\n\n**Process and methodology**\n- Close collaboration with city planning and engineering teams to ensure safety and feasibility\n- Zone-by-zone commissioning and alignment to optimize experience across the entire tunnel length\n- Comprehensive testing and calibration to ensure reliable operation during high-traffic periods\n\n\n---"
    },
    {
        "id": "orchestre-symphonique-de-montréal",
        "title": "ORCHESTRE SYMPHONIQUE DE MONTRÉAL",
        "year": null,
        "client": "Moment Factory / MONTRÉAL",
        "role": null,
        "technologies": null,
        "description": "Visuel en temps réel + Danseur",
        "impact": null,
        "media": [
            "https://www.instagram.com/osmconcerts/"
        ],
        "instagram": [
            "https://www.instagram.com/osmconcerts/"
        ],
        "cover": null,
        "hasMedia": false
    },
    {
        "id": "universal-studios",
        "title": "UNIVERSAL STUDIOS",
        "year": null,
        "client": "Moment Factory / ORLANDO",
        "role": null,
        "technologies": null,
        "description": "R&D Détection de mouvement et installations interactives",
        "impact": null,
        "media": [
            "https://www.instagram.com/universalorlando/"
        ],
        "instagram": [
            "https://www.instagram.com/universalorlando/"
        ],
        "cover": null,
        "hasMedia": false
    },
    {
        "id": "ey-innovation-realized",
        "title": "EY INNOVATION REALIZED",
        "year": null,
        "client": "Moment Factory / SAN FRANCISCO",
        "role": null,
        "technologies": null,
        "description": "Visuel en temps réel + Danseur",
        "impact": null,
        "media": [
            "https://www.instagram.com/ey_global/"
        ],
        "instagram": [
            "https://www.instagram.com/ey_global/"
        ],
        "cover": null,
        "hasMedia": false
    },
    {
        "id": "tabegami-sama",
        "title": "TABEGAMI SAMA",
        "year": null,
        "client": "Moment Factory / TOKYO",
        "role": null,
        "technologies": null,
        "description": "Exposition interactive",
        "impact": null,
        "media": [
            "https://www.instagram.com/momentfactory/"
        ],
        "instagram": [
            "https://www.instagram.com/momentfactory/"
        ],
        "cover": null,
        "hasMedia": true,
        "fullDescription": "An interactive projection inspired by Japanese folklore of nourishment—an invented ‘deity’ that responds to offerings of gesture and presence.\n\nTechnical details and implementation\n- Projection mapping onto sculptural/ritual surface.\n- Audio narrative and sensor triggers for call‑and‑response.\n\nChallenges and solutions\n- Respectful cultural framing and metaphor.\n- Precise mapping to complex surface geometry.\n\nImpact and results\n- Invited audiences to embody ritual through playful technology.\n- Expanded the practice into food/culture thematics.\n\nProcess and methodology\n- Motif research and consultation.\n- Prototype altar interactions; calibrate proximity sensors.\n\n\n---"
    },
    {
        "id": "ozone",
        "title": "OZONE",
        "year": null,
        "client": "Biennale de Montréal @ Le Livart / MONTREAL",
        "role": null,
        "technologies": null,
        "description": "Installation interactive",
        "impact": null,
        "media": [],
        "instagram": [],
        "cover": null,
        "hasMedia": true,
        "fullDescription": "A contemplative visualization of atmospheric data—ozone, pollution and weather rendered as shifting abstract fields rather than charts.\n\nTechnical details and implementation\n- Real‑time environmental data inputs; normalized and smoothed.\n- Abstract visual grammars mapped to indices; projection/screen display.\n\nChallenges and solutions\n- Data reliability and gaps → caching and graceful degradation.\n- Avoiding literalism while keeping meaning → legend and pacing.\n\nImpact and results\n- Encouraged reflective engagement with climate metrics.\n- Demonstrated poetic data art without didactic graphs.\n\nProcess and methodology\n- Data schema design and unit handling.\n- A/B tests for visual comprehensibility at distance.\n\n\n---"
    },
    {
        "id": "red-hot-chili-peppers-getaway-tour",
        "title": "RED HOT CHILI PEPPERS GETAWAY TOUR",
        "year": null,
        "client": "Moment Factory / WORLD",
        "role": null,
        "technologies": null,
        "description": "Visuel en temps réel + Éclairage cinétique",
        "impact": null,
        "media": [
            "https://www.instagram.com/chilipeppers/"
        ],
        "instagram": [
            "https://www.instagram.com/chilipeppers/"
        ],
        "cover": null,
        "hasMedia": true,
        "fullDescription": "Arena tour visuals blending live camera with generative overlays tuned to the band’s high‑energy set—designed to read clearly to the back rows.\n\nTechnical details and implementation\n- TouchDesigner effects on camera feeds; LED wall delivery.\n- Color and rhythm cues coordinated with lighting director.\n\nChallenges and solutions\n- Venue variability and rapid load‑ins.\n- Keeping compositions legible amid fast edits and lights.\n\nImpact and results\n- Raised production intensity without drowning the players.\n- Portable package adapted across continents.\n\nProcess and methodology\n- Template looks per song; notes for day‑of changes.\n- On‑the‑fly operator macros for solos/transitions.\n\n\n---"
    },
    {
        "id": "nova-lumina",
        "title": "NOVA LUMINA",
        "year": null,
        "client": "Moment Factory / CHANDLER",
        "role": null,
        "technologies": null,
        "description": "Parcours immersif et installation interactive",
        "impact": null,
        "media": [
            "https://www.instagram.com/momentfactory/"
        ],
        "instagram": [
            "https://www.instagram.com/momentfactory/"
        ],
        "cover": null,
        "hasMedia": true,
        "fullDescription": "A night walk in Chandler, Québec that narrates a celestial encounter along a riverside trail—light, sound and projection sequenced as stations in a journey.\n\nTechnical details and implementation\n- Distributed outdoor projection/lighting and spatialized sound.\n- Narrative sequencing across multiple stations.\n\nChallenges and solutions\n- Weatherproof operation over long seasons.\n- Managing large nightly visitor throughput.\n\nImpact and results\n- Became a cultural tourism anchor for the region.\n- Offered families a shared media art experience in nature.\n\nProcess and methodology\n- Trail design and station storyboards.\n- Lighting zones, power and maintenance cycles.\n\n\n---"
    },
    {
        "id": "aura",
        "title": "AURA",
        "year": null,
        "client": "MONTRÉAL EN LUMIÈRES / MONTRÉAL",
        "role": null,
        "technologies": null,
        "description": "Espace extérieur immersif. Projection architecturale",
        "impact": null,
        "media": [
            "https://www.instagram.com/momentfactory/"
        ],
        "instagram": [
            "https://www.instagram.com/momentfactory/"
        ],
        "cover": null,
        "hasMedia": true,
        "fullDescription": "Inside Montreal's Notre-Dame Basilica, architecture becomes a living canvas where projection and music articulate the building's sacred forms. This permanent installation honors the basilica's spiritual character while making its ornate architecture newly perceivable through light and sound, creating an immersive experience that has become immensely popular with visitors.\n\n**Technical details and implementation**\n- Large-scale interior projection mapping system designed specifically for the basilica's complex architecture\n- Multi-channel sound system creating immersive audio that complements the visual experience\n- Permanent infrastructure with careful mounting and alignment to preserve historic materials\n- Sophisticated content creation pipeline that respects the building's sacred character\n\n**Challenges and solutions**\n- Respecting sacred space and historic materials required careful planning and preservation-safe installation practices\n- Creating rendering that flatters ornate surfaces without glare demanded precise projection mapping and content design\n- Balancing artistic vision with religious sensitivity required ongoing collaboration with church authorities\n\n**Impact and results**\n- Achieved immense public popularity and became a long-running cultural program\n- Successfully helped reposition the Basilica as a major cultural venue in Montreal\n- Demonstrated how technology can enhance rather than diminish the spiritual experience of sacred spaces\n\n**Process and methodology**\n- Comprehensive 3D scanning and content creation specifically authored to the basilica's unique geometry\n- Iterative after-hours calibration and testing to ensure optimal experience without disrupting services\n- Development of preservation-safe installation practices that protect historic materials and surfaces\n\n\n---"
    },
    {
        "id": "en-route-vers-les-jutras",
        "title": "EN ROUTE VERS LES JUTRAS",
        "year": null,
        "client": "Société des arts technologiques / MONTRÉAL",
        "role": null,
        "technologies": null,
        "description": "Vjing",
        "impact": null,
        "media": [
            "https://www.instagram.com/sat_montreal/"
        ],
        "instagram": [
            "https://www.instagram.com/sat_montreal/"
        ],
        "cover": null,
        "hasMedia": false
    },
    {
        "id": "basel-2022",
        "title": "BASEL 2022 PROJECTS",
        "year": "2022",
        "client": "Rafael Lozano-Hemmer / Basel",
        "role": null,
        "technologies": null,
        "description": "Thermal imaging and interactive installations",
        "impact": null,
        "media": [
            "https://www.instagram.com/lozanohemmer/"
        ],
        "instagram": [
            "https://www.instagram.com/lozanohemmer/"
        ],
        "cover": null,
        "hasMedia": true,
        "fullDescription": "A focused art‑fair presentation including editions of Thermal Drift and related works, tailored to fair constraints while preserving impact.\n\nTechnical details and implementation\n- Editioned builds optimized for booth light and viewing distance.\n- Compact, reliable show control for long open hours.\n\nChallenges and solutions\n- High traffic and transient viewing → immediate legibility.\n- Tight install/strike windows and shipping constraints.\n\nImpact and results\n- Connected works with collectors and curators; led to sales.\n- Expanded presence in the international fair circuit.\n\nProcess and methodology\n- Pre‑packaged crates and checklists.\n- In‑booth calibration and heat‑management for equipment.\n\n\n---"
    },
    {
        "id": "halte-0-sepaq-iles-de-boucherville",
        "title": "HALTE 0 SÉPAQ ÎLES-DE-BOUCHERVILLE",
        "year": null,
        "client": "SÉPAQ / MONTRÉAL",
        "role": null,
        "technologies": null,
        "description": "Architecture + Interactivité",
        "impact": null,
        "media": [],
        "instagram": [],
        "cover": null,
        "hasMedia": true,
        "fullDescription": "An outdoor projection along the water that celebrates Québec’s natural heritage. The site itself—wind, water, insects—becomes part of the piece’s motion picture.\n\nTechnical details and implementation\n- Projection mapping onto terrain/structures; nature‑recording‑infused sound.\n- Weatherized enclosures; long‑throw projection across water.\n\nChallenges and solutions\n- Outdoor unpredictability → robust housings, anti‑condensation, remote monitoring.\n- Visitor safety and path lighting while preserving darkness.\n\nImpact and results\n- Expanded park programming; brought new audiences after dark.\n- A gentle, respectful intervention in a protected landscape.\n\nProcess and methodology\n- Site surveys; throw tests across water; power routing.\n- Evening‑of adjustments for wind, haze, and wildlife activity.\n\n\n---"
    },
    {
        "id": "interactive-basketball",
        "title": "INTERACTIVE BASKETBALL",
        "year": null,
        "client": "Moment Factory / MONTRÉAL",
        "role": null,
        "technologies": null,
        "description": "High Speed Tracking - Using Panasonic high speed projector and tracking system",
        "impact": null,
        "media": [],
        "instagram": [],
        "cover": null,
        "hasMedia": false
    },
    {
        "id": "my-morning-jacket",
        "title": "MY MORNING JACKET",
        "year": null,
        "client": "YouTube / WORLD",
        "role": null,
        "technologies": null,
        "description": "Video frame extraction from live performance",
        "impact": null,
        "media": [],
        "instagram": [],
        "cover": null,
        "hasMedia": false
    }
];
